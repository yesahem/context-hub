use std::path::PathBuf;

use crate::core::git::{CommitInfo, GitAnalyzer};
use crate::core::llm::{ExtractedContext, LlmProcessor};
use crate::core::storage::{Storage, GlobalContext};
use crate::utils::config::Config;

pub struct ContextProcessor {
    pub git: GitAnalyzer,
    llm: LlmProcessor,
    storage: Storage,
    config: Config,
}

impl ContextProcessor {
    pub fn new(repo_path: &PathBuf, config: Config) -> anyhow::Result<Self> {
        let git = GitAnalyzer::new(repo_path)?;
        let storage = Storage::new(&repo_path.join(".contexthub/context.db"))?;
        let llm = LlmProcessor::new(config.ollama.clone());
        
        Ok(Self {
            git,
            llm,
            storage,
            config,
        })
    }

    pub fn get_commits(&self, limit: usize) -> anyhow::Result<Vec<CommitInfo>> {
        self.git.get_commit_history(limit)
    }

    pub fn get_commit_range(&self, from: &str, to: &str) -> anyhow::Result<Vec<CommitInfo>> {
        self.git.get_commit_range(from, to)
    }

    /// Check if a commit has already been stored (for dedup)
    pub fn has_commit(&self, commit_hash: &str) -> anyhow::Result<bool> {
        self.storage.has_commit(commit_hash)
    }

    pub async fn process_commit(&self, commit: &CommitInfo) -> anyhow::Result<ExtractedContext> {
        let diff = self.git.get_diff(&commit.hash)?;

        // Estimate token count and truncate diff if necessary
        let max_tokens = self.config.context.max_tokens_per_commit;
        let estimated_tokens = diff.len() / 4; // rough chars-to-tokens ratio
        let diff = if estimated_tokens > max_tokens {
            let max_chars = max_tokens * 4;
            let truncated = &diff[..max_chars.min(diff.len())];
            format!("{}\n\n[... diff truncated, {} tokens estimated, limit {}]", truncated, estimated_tokens, max_tokens)
        } else {
            diff
        };

        let files: Vec<String> = diff
            .lines()
            .filter(|l| l.starts_with("+++ b/") || l.starts_with("--- a/"))
            .map(|l| l.replace("+++ b/", "").replace("--- a/", ""))
            .collect::<std::collections::HashSet<_>>()
            .into_iter()
            .collect();

        // Fetch previous context for incremental chaining
        let previous_context = self.storage.get_latest_context_summary()?;

        let context = self.llm
            .extract_context(
                &commit.message,
                &diff,
                &files,
                previous_context.as_deref(),
            )
            .await?;

        // Store full ExtractedContext as JSON in llm_extracted_context column
        let extracted_json = serde_json::to_string(&context)?;

        self.storage.store_global_context(
            commit,
            &context.summary,
            &files,
            &extracted_json,
        )?;

        self.storage.store_ttl_memory(
            &commit.hash,
            &context.summary,
            self.config.context.ttl_days,
        )?;

        Ok(context)
    }

    pub fn get_global_context(&self) -> anyhow::Result<Vec<GlobalContext>> {
        self.storage.get_global_context()
    }

    #[allow(dead_code)]
    pub fn get_global_context_since(&self, commit_hash: &str) -> anyhow::Result<Vec<GlobalContext>> {
        self.storage.get_global_context_since(commit_hash)
    }

    pub fn export_context_markdown(&self) -> anyhow::Result<String> {
        let contexts = self.storage.get_global_context()?;
        
        let mut output = String::from("# Repository Context\n\n");
        output.push_str("## Recent Changes\n\n");
        
        for ctx in contexts.iter().take(20) {
            output.push_str(&format!("### {}: {}\n", 
                &ctx.commit_hash[..7.min(ctx.commit_hash.len())],
                ctx.commit_message.lines().next().unwrap_or("No message")
            ));
            output.push_str(&format!("- **Date:** {}\n", ctx.commit_date.format("%Y-%m-%d")));
            output.push_str(&format!("- **Summary:** {}\n", ctx.context_summary));
            
            if !ctx.files_changed.is_empty() {
                let files: Vec<String> = serde_json::from_str(&ctx.files_changed)
                    .unwrap_or_default();
                output.push_str(&format!("- **Files:** {}\n", files.join(", ")));
            }
            output.push('\n');
        }
        
        Ok(output)
    }

    pub fn export_context_json(&self) -> anyhow::Result<String> {
        let contexts = self.storage.get_global_context()?;
        let json = serde_json::to_string_pretty(&contexts)?;
        Ok(json)
    }

    /// Export context in CLAUDE.md format (for Claude Code / Claude AI)
    pub fn export_for_claude(&self) -> anyhow::Result<String> {
        let contexts = self.storage.get_global_context()?;
        let mut out = String::from("# CLAUDE.md — Project Context for Claude\n\n");
        out.push_str("This file was auto-generated by ContextHub to help Claude understand this repository.\n\n");
        out.push_str("## Project Overview\n\n");
        out.push_str(&self.build_project_summary(&contexts));
        out.push_str("\n## Recent Changes\n\n");
        for ctx in contexts.iter().take(30) {
            out.push_str(&format!("- **{}** ({}): {}\n",
                &ctx.commit_hash[..7.min(ctx.commit_hash.len())],
                ctx.commit_date.format("%Y-%m-%d"),
                ctx.context_summary,
            ));
        }
        out.push_str("\n## Key Technologies\n\n");
        out.push_str(&self.extract_technologies(&contexts));
        Ok(out)
    }

    /// Export context in .cursorrules format (for Cursor IDE)
    pub fn export_for_cursor(&self) -> anyhow::Result<String> {
        let contexts = self.storage.get_global_context()?;
        let mut out = String::from("# Cursor Rules — Auto-generated by ContextHub\n\n");
        out.push_str("## Project Context\n\n");
        out.push_str(&self.build_project_summary(&contexts));
        out.push_str("\n## Recent Development Activity\n\n");
        for ctx in contexts.iter().take(20) {
            out.push_str(&format!("- {}: {}\n",
                &ctx.commit_hash[..7.min(ctx.commit_hash.len())],
                ctx.context_summary,
            ));
        }
        out.push_str("\n## Technologies\n\n");
        out.push_str(&self.extract_technologies(&contexts));
        Ok(out)
    }

    /// Export context for GitHub Copilot (.github/copilot-instructions.md)
    pub fn export_for_copilot(&self) -> anyhow::Result<String> {
        let contexts = self.storage.get_global_context()?;
        let mut out = String::from("# Copilot Instructions — Auto-generated by ContextHub\n\n");
        out.push_str("## Repository Context\n\n");
        out.push_str(&self.build_project_summary(&contexts));
        out.push_str("\n## Recent Changes Summary\n\n");
        for ctx in contexts.iter().take(15) {
            out.push_str(&format!("- {}\n", ctx.context_summary));
        }
        out.push_str("\n## Technologies & Patterns\n\n");
        out.push_str(&self.extract_technologies(&contexts));
        Ok(out)
    }

    /// Build a project summary from stored contexts
    fn build_project_summary(&self, contexts: &[GlobalContext]) -> String {
        if contexts.is_empty() {
            return "No context available yet.\n".to_string();
        }

        // Collect all file paths to infer project structure
        let mut all_files: Vec<String> = Vec::new();
        for ctx in contexts.iter().take(50) {
            if let Ok(files) = serde_json::from_str::<Vec<String>>(&ctx.files_changed) {
                all_files.extend(files);
            }
        }
        all_files.sort();
        all_files.dedup();

        let mut summary = String::new();
        if !all_files.is_empty() {
            summary.push_str(&format!("This project has had {} context entries extracted from git commits.\n", contexts.len()));
            summary.push_str(&format!("Files touched across analyzed commits: {}\n\n", all_files.len()));
            summary.push_str("Key files:\n");
            for f in all_files.iter().take(20) {
                summary.push_str(&format!("- {}\n", f));
            }
            summary.push('\n');
        }
        summary
    }

    /// Extract unique technologies from stored ExtractedContext JSON
    fn extract_technologies(&self, contexts: &[GlobalContext]) -> String {
        let mut techs: std::collections::HashSet<String> = std::collections::HashSet::new();

        for ctx in contexts.iter().take(50) {
            if let Ok(extracted) = serde_json::from_str::<crate::core::llm::ExtractedContext>(&ctx.llm_extracted_context) {
                for tech in &extracted.technologies {
                    techs.insert(tech.clone());
                }
            }
        }

        if techs.is_empty() {
            return "No technology information extracted yet.\n".to_string();
        }

        let mut sorted: Vec<String> = techs.into_iter().collect();
        sorted.sort();
        sorted.iter().map(|t| format!("- {}\n", t)).collect()
    }

    pub fn is_ollama_running(&self) -> bool {
        self.llm.is_ollama_running()
    }

    pub fn get_last_commit(&self) -> anyhow::Result<Option<String>> {
        self.storage.get_last_processed_commit()
    }

    pub fn get_context_count(&self) -> anyhow::Result<usize> {
        self.storage.get_context_count()
    }
}
